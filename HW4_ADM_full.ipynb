{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractring_page(url):\n",
    "    try:\n",
    "        l=[]\n",
    "        soup=BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            y=soup.findAll('p',{'titolo text-primary'})\n",
    "            for house in y:\n",
    "                s='https://www.immobiliare.it'\n",
    "                s1=house.contents[1]['href']\n",
    "                if s1.startswith(\"https\")==False:\n",
    "                    s1=s+s1\n",
    "                l.append(s1)\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        l=['The page does not exit']\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]\n",
    "for i in range(600):\n",
    "    url = 'https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag='+str(i+1)\n",
    "    link.append(extractring_page(url))\n",
    "link=reduce(lambda x,y: x+y,link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1=pd.DataFrame()\n",
    "link1['links']=link\n",
    "link.to_csv(\"Scrappinglink.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.read_csv(\"Scrappinglink.csv\")\n",
    "l=list(l['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective_page(url):\n",
    "    try:\n",
    "        tag=BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "        time.sleep(2)\n",
    "        l1=['piano','bagni','superficie','locali']\n",
    "        df=[]\n",
    "        x=tag.findAll('div',{'class':'im-property__features'})\n",
    "        y=tag.findAll('div',{'class':'clearfix description'})\n",
    "        d={}\n",
    "        house=[text for text in x[0].stripped_strings]\n",
    "        house.reverse()\n",
    "        house1=[text for text in y[0].stripped_strings]\n",
    "        house1=\" \".join(house1)\n",
    "        for i in l1:\n",
    "            if i in house:\n",
    "                index=house.index(i)\n",
    "                if i=='superficie':\n",
    "                    d[i]=house[index+3]\n",
    "                else:\n",
    "                    d[i]=house[index+1]\n",
    "                if house[-1].find('€')!=-1:\n",
    "                    d['prezzo(€)']=house[-1]\n",
    "        d['description']=house1\n",
    "    except:\n",
    "        d['description']=\"there was a problem in this link\"\n",
    "    del tag\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "with Pool(5) as p:\n",
    "    records = p.map(Objective_page, l)\n",
    "p.terminate()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame.from_dict(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Scraping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
